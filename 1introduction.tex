% !TEX root =  main.tex
\chapter{Introduction}
\label{chap:intro}

This study explores the use of compressive sensing (CS), an emergent sampling theorem that allows reconstruction of signals from much fewer samples than required by the Nyquist-Shannon sampling theorem (NST). In this framework, the computational burden of encoding/decoding a signal is shifted from the sampling device to the device performing reconstruction, decompression, or other modes of post-processing. As such, there exist many ways to reconstruct a signal from compressive measurements.

CS has found its applications in simple audio signals containing stable frequencies (such as pure tones \cite{Mathew2016,Andras2018}) and dynamic frequencies (such as speech \cite{Low2013,Low2018,Abrol2015}), images \cite{Mo2013,Zhou2016,Romero2016}, and grayscale videos \cite{Liu2014,Chen2014}. The formulation of a sensing matrix in CS requires a basis conforming to some uniform uncertainty principle, and most common starting points would be partial discrete cosine transform (DCT) matrices or partial discrete wavelet transform (DWT) matrices.


\section{Related literature}
\label{sec:rrl}
In 2004, Cand\`{e}s, Romberg, Tao \cite{Candes2006}, and Donoho \cite{Donoho2006} both asked and answered the questions that birthed the field which we now know as compressive sensing. The methods in CS apply concepts from time-frequency uncertainty principles \cite{Donoho2001} and sparse representations, which were studied rigorously by Donoho and Elad \cite{Donoho2003}.

Linh-Trung et al.~\cite{LinhTrung2008} demonstrated the use of deterministic chaos filters to acquire samples instead of random distributions. Normally, a deterministic chaotic function needs one or more initial value parameters, and the sequence produced by different combinations of initial values rapidly diverge from each other. This phenomenon led to investigation of the use of CS as an encryption algorithm. Simultaneous compression and encryption was achieved by \cite{Zhou2016}, and it was found that the produced sequences were sensitive to initial value perturbations on the order of $10^{-15}$. Their image compression-encryption model via CS was shown to have a key space on the order of $10^{83}$, making it extremely resistant to brute force and other types of attacks. In this study, a logistic map was used to encode and construct the sensing matrix. The encryption system exhibited similar key sensitivity and robustness characteristics mentioned in the former. In the methods above, including those in this study, sampling was performed in the signal domain (i.e., temporal domain for audio, spatial domain for images), and the reconstruction was performed in the frequency domain.

Whereas images are not naturally bandlimited and rather, are dependent on the spatial resolution and bit depth of the imaging device, audio size scales proportionally with time and takes on a wider range of values. The accepted frequency range of human hearing is from 20~Hz to 20~kHz, so by the NST, a sampling frequency greater than 40~kHz is needed to ensure that an audio sample is recorded completely. Any meaningful audio recording, especially those containing speech, will certainly have a significant duration, so one cannot straightforwardly apply methodologies used for images. The first challenge this would pose for electronic systems is insufficient memory to process the entire signal all at once. Low circumvented this problem \cite{Low2013,Low2018} by transforming the signal to the modulation domain, essentially raising a one-dimensional signal to $N$-dimensions, where $N$ is dependent on the desired spectrogram resolution and number of subbands. This method was adopted in this study, and additionally, each subband was multiplied with a window function to suppress potential boundary artifacts when reconstructing. In earlier experiments, reconstruction would often completely fail when windowing was not used. In the cases, however, that were successful, the reconstruction exhibited severe boundary artifacts in the form of distortion, aliasing, or noise.


\section{Novelty}
\label{sec:novel}
This study aims to provide a generalization for applying CS techniques to signals of arbitrary dimensions, for applications such as compression, encryption, and enhancement. Contemporary CS research work exclusively on either audio or image signals, and, due to the computational demands, focus on constructing effective sensing matrices, optimizing the computational complexity for real-time applications, and improving reconstruction quality. In the establishment of CS methods, two different general frameworks arise for image and audio signals.

Furthermore, current research tend to evaluate signal reconstruction quality using statistical metrics, such as mean-squared error (MSE) and its variants. Arguably, the final interpreter of all signals are humans, and it is important to be able to tell how well any compressive/reconstructive algorithm performs just by looking at the metrics without directly observing the signal contents. In light of this, the study also aims to evaluate the reconstruction quality of CS algorithms using perceptually accurate metrics. This class of objective metrics are usually built upon now-obsolete subjective scoring systems, and allows human observers to make an informed estimate of the signal quality without directly accessing the signal itself.

Finally, this study is conducted in order to lay out a unified, standardized workflow for similar applications of CS on signals with arbitrary content. This includes signals containing a combination of audio and images, such as color videos and hyperspectral images.


\section{Thesis overview}
\label{sec:overview}
The next chapter establishes the relevant mathematical concepts and notation to be used throughout this study, algorithms used in signal reconstruction, and appropriate metrics per type of signal. Chapter~3 establishes basic workflows and studies the effect of random sampling on CS reconstruction. Chapters~4 \& 5 respectively focus on image-based CS and audio-based CS. Each of these chapters are self-contained methodologies, results, and discussions to emphasize that the methods can work independently of each other. Conclusions of the study and recommendations for future studies are presented in Chapter~6.