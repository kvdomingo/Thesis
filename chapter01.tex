The recent trend of curiosity-driven human development has caused a surge in the amount of openly accessible data. More often than not, the inflow of information into digital systems happens much faster than the system can process the data. Moore's law implicitly sets a limit to how powerful and how quick our electronic systems can become (barring a significant breakthrough in the field of quantum computing), and the Nyquist-Shannon sampling theorem (NST) limits the range of frequencies a certain device can successfully recover. This study explores the use of compressed sensing (CS)---an emergent sampling theorem that allows recovery of signals from much fewer samples than required by the NST---as a viable sampling method for signals with an arbitrary number of dimensions. In this framework, the computational burden is shifted from the sampling device to the device performing reconstruction/decompression, and as such, there exist many ways to recover a signal from compressive measurements. The use of CS has been applied to simple audio signals containing pure tones \cite{Mathew2016,Andras2018} and speech \cite{Low2013,Low2018,Abrol2015}, images \cite{Mo2013,Zhou2016,Romero2016}, and videos \cite{Liu2014,Chen2014}. Common implementations of CS utilize analytical measurement bases such as the discrete cosine transform (DCT) basis, but recent studies \cite{Liu2013,Sharma2018,Eslahi2016} have shown that learned bases perform much better on more complex signals. The learning algorithms associated with these bases range from the classical iterative methods, such as matching pursuit (MP) and principal components analysis (PCA), to the more contemporary machine learning methods, most notably recurrent neural networks (RNN) and associative memory neural networks (AMNN). The novelty of this study is to provide a generalization of compressive sensing methods on signals of arbitrary dimensions, and to mathematically bridge the learning phase of neural networks with compressive sensing.


\section{Related literature}
\label{sec:rrl}
In 2006, Cand\`{e}s, Romberg, Tao \cite{Candes2006}, and Donoho \cite{Donoho2006} kicked off the field of compressive sensing by answering the following question: ``With the recent breakthroughs in lossy compression technologies, we now know that most of the data we acquire can be thrown away with minimal perceptual loss. Why bother to acquire all the data when we can just directly measure the part that will not be thrown away?'' The methods in CS apply concepts from time-frequency uncertainty principles \cite{Donoho2001} and sparse representations \cite{Donoho2003}. CS can be viewed as a random undersampling method, where the sampling rate can be associated with a quasi-frequency which is significantly lower than the Nyquist rate, and the random samples usually follow Gaussian or uniform distribution. \cite{LinhTrung2008} demonstrated the use of deterministic chaos filters to acquire samples instead of random distributions. The chaotic behavior of the sampling function was used to achieve simultaneous compression and encryption in \cite{Mo2013}, and was extended in \cite{Zhou2016} to utilize higher-dimensional chaotic systems. Sampling using chaotic maps were applied to acoustic signals in \cite{Mathew2016}. In the methods above, sampling was performed in the real domain (i.e., time domain for audio, spatial domain for images), and the reconstruction was performed in the frequency domain. \cite{Andras2018} proposed a method to perform both sampling and reconstruction in the time domain using differential evolution.

The application of CS for signal denoising was explored in \cite{Dabov2007}, and for recorded speech enhancement in \cite{Low2013}. Aside from the frequency domain, signals have been shown to be sparse in the modulation domain as well, which is a more appropriate representation for speech signals \cite{Low2018} that contain voiced, nonvoiced, and noise regions which may vary rapidly in time.

Due to the relatively large size of video information---as a consequence of its high dimensionality---it is impractical to apply image CS techniques on an entire frame-by-frame basis. Correlations between adjacent frames are utilized instead, and can be obtained using dictionary learning \cite{Liu2013} or PCA \cite{Liu2014}. Once again, due to its high dimensionality, the application of CS to videos naturally led researchers to look towards machine learning methods \cite{Iliadis2018,Yao2019}.


\section{Novelty}
\label{sec:novel}